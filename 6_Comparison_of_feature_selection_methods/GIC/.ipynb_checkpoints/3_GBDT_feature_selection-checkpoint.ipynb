{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11959,)\n",
      "(296, 11959)\n",
      "(296,)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('../../data/oversampled_data.npy', allow_pickle=True)\n",
    "gene = np.load('../../data/geneAfterDiscard_0.npy', allow_pickle=True)\n",
    "\n",
    "feature = data[:, :-1]\n",
    "label = data[:, -1]\n",
    "print(gene.shape)\n",
    "print(feature.shape)\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Calculate the importance of genes.\n",
    "+ The feature importance of each gene was calculated using the GBDT algorithm.\n",
    "+ 100 experiments were performed to mitigate the effect of randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.9999999999999998\n",
      "1 0.9999999999999999\n",
      "2 1.0\n",
      "3 1.0000000000000002\n",
      "4 1.0\n",
      "5 1.0\n",
      "6 1.0\n",
      "7 1.0000000000000002\n",
      "8 1.0\n",
      "9 1.0000000000000002\n",
      "10 1.0\n",
      "11 1.0\n",
      "12 1.0\n",
      "13 0.9999999999999999\n",
      "14 1.0\n",
      "15 1.0\n",
      "16 1.0\n",
      "17 0.9999999999999999\n",
      "18 1.0\n",
      "19 0.9999999999999998\n",
      "20 1.0000000000000002\n",
      "21 1.0\n",
      "22 1.0\n",
      "23 1.0\n",
      "24 1.0\n",
      "25 1.0\n",
      "26 1.0\n",
      "27 1.0\n",
      "28 1.0\n",
      "29 0.9999999999999999\n",
      "30 1.0\n",
      "31 1.0\n",
      "32 0.9999999999999999\n",
      "33 1.0\n",
      "34 0.9999999999999999\n",
      "35 1.0\n",
      "36 1.0\n",
      "37 1.0\n",
      "38 0.9999999999999999\n",
      "39 1.0\n",
      "40 1.0\n",
      "41 1.0000000000000002\n",
      "42 1.0\n",
      "43 1.0\n",
      "44 1.0\n",
      "45 1.0\n",
      "46 1.0\n",
      "47 1.0\n",
      "48 0.9999999999999999\n",
      "49 1.0\n",
      "50 0.9999999999999999\n",
      "51 1.0\n",
      "52 1.0\n",
      "53 0.9999999999999999\n",
      "54 1.0\n",
      "55 1.0\n",
      "56 0.9999999999999999\n",
      "57 1.0\n",
      "58 1.0\n",
      "59 1.0\n",
      "60 1.0\n",
      "61 1.0\n",
      "62 1.0\n",
      "63 1.0000000000000002\n",
      "64 1.0\n",
      "65 1.0\n",
      "66 0.9999999999999999\n",
      "67 0.9999999999999999\n",
      "68 1.0\n",
      "69 1.0\n",
      "70 1.0\n",
      "71 0.9999999999999999\n",
      "72 0.9999999999999999\n",
      "73 0.9999999999999999\n",
      "74 1.0000000000000002\n",
      "75 0.9999999999999999\n",
      "76 1.0\n",
      "77 1.0\n",
      "78 0.9999999999999998\n",
      "79 1.0\n",
      "80 1.0\n",
      "81 0.9999999999999999\n",
      "82 1.0\n",
      "83 1.0\n",
      "84 1.0\n",
      "85 1.0\n",
      "86 0.9999999999999999\n",
      "87 0.9999999999999999\n",
      "88 1.0\n",
      "89 1.0000000000000002\n",
      "90 1.0000000000000002\n",
      "91 1.0\n",
      "92 1.0\n",
      "93 1.0\n",
      "94 1.0\n",
      "95 1.0\n",
      "96 1.0000000000000002\n",
      "97 1.0\n",
      "98 1.0\n",
      "99 0.9999999999999999\n",
      "duration:3453.16961812973\n"
     ]
    }
   ],
   "source": [
    "# repeated experiments\n",
    "runNum = 100\n",
    "\n",
    "imp = []\n",
    "tic = time.time()\n",
    "\n",
    "for i in range(runNum):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature, label, test_size=0.3, shuffle=True)\n",
    "\n",
    "    fs = GradientBoostingClassifier()\n",
    "    fs.fit(X_train, y_train)\n",
    "    imp.append(fs.feature_importances_)\n",
    "    print(i, fs.feature_importances_.sum())\n",
    "\n",
    "toc = time.time()\n",
    "duration = toc-tic\n",
    "print(f'duration:{duration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calculating feature importance\n",
    "\n",
    "imp = np.array(imp)\n",
    "\n",
    "\"\"\"\n",
    "Because the characteristics of each experiment are not equal in importance, \n",
    "in order to ensure the equality of each experiment,\n",
    "Here, the sum of the characteristic importance of each experiment is 1\n",
    "\"\"\"\n",
    "\n",
    "for i in range(imp.shape[0]):\n",
    "    rowSum = imp[i].sum()\n",
    "    imp[i] /= rowSum\n",
    "\n",
    "np.save(\"NormalizedImp100.npy\", imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
